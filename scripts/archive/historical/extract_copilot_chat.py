#!/usr/bin/env python3
"""
Extract VS Code GitHub Copilot Chat Conversations
==================================================

SELF-CONTAINED script to extract Copilot chat conversations from any VS Code
workspace into a clean Markdown file optimized for LLM consumption.

Features:
- Auto-detects current workspace from CWD
- Handles special characters (Unicode, emoji, escape sequences)
- Preserves tables and code blocks
- Detects milestones (, DONE, COMPLETED, etc.)
- Works with any conversation - just run from any workspace

Usage:
    python scripts/extract_copilot_chat.py              # Export largest session from CWD workspace
    python scripts/extract_copilot_chat.py --all        # Export all sessions
    python scripts/extract_copilot_chat.py --workspace "ProjectName"  # Specific workspace

Author: Generated by GitHub Copilot (Claude Opus 4.5)
Date: December 27, 2025
"""

import argparse
import html
import json
import os
import re
import sys
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any


# ============================================================================
# CONFIGURATION
# ============================================================================

# VS Code data paths (macOS, Linux, Windows)
VSCODE_PATHS = {
    "darwin": {
        "insiders": Path.home() / "Library/Application Support/Code - Insiders",
        "stable": Path.home() / "Library/Application Support/Code",
    },
    "linux": {
        "insiders": Path.home() / ".config/Code - Insiders",
        "stable": Path.home() / ".config/Code",
    },
    "win32": {
        "insiders": Path.home() / "AppData/Roaming/Code - Insiders",
        "stable": Path.home() / "AppData/Roaming/Code",
    },
}

# Milestone detection patterns
MILESTONE_PATTERNS = [
    (r"", "COMPLETED"),
    (r"", "COMPLETED"),
    (r"\bDONE\b", "DONE"),
    (r"\bCOMPLETED?\b", "COMPLETED"),
    (r"\bFIXED\b", "FIXED"),
    (r"\bIMPLEMENTED\b", "IMPLEMENTED"),
    (r"\bVERIFIED\b", "VERIFIED"),
    (r"\bSHIPPED\b", "SHIPPED"),
    (r"", "SHIPPED"),
    (r"", "WARNING"),
    (r"", "FAILED"),
    (r"\bFAILED\b", "FAILED"),
    (r"\bBLOCKED\b", "BLOCKED"),
]


# ============================================================================
# TEXT PROCESSING
# ============================================================================

def sanitize_text(text: str) -> str:
    """
    Sanitize text for Markdown output.
    Handles special characters, escape sequences, and Unicode normalization.
    """
    if not text:
        return ""
    
    # Normalize Unicode (NFC form - composed characters)
    text = unicodedata.normalize("NFC", text)
    
    # Decode common escape sequences
    try:
        # Handle \\n, \\t etc. that might be double-escaped
        text = text.encode("utf-8").decode("unicode_escape", errors="ignore")
    except (UnicodeDecodeError, UnicodeEncodeError):
        pass
    
    # Remove null bytes and other control characters (except newline, tab)
    text = re.sub(r"[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]", "", text)
    
    # Fix broken surrogate pairs
    text = text.encode("utf-8", errors="surrogatepass").decode("utf-8", errors="replace")
    
    return text


def detect_milestones(text: str) -> List[str]:
    """Detect milestone markers in text."""
    milestones = []
    for pattern, label in MILESTONE_PATTERNS:
        if re.search(pattern, text, re.IGNORECASE):
            milestones.append(label)
    return list(set(milestones))


def preserve_tables(text: str) -> str:
    """Ensure Markdown tables are properly formatted."""
    lines = text.split("\n")
    result = []
    in_table = False
    
    for line in lines:
        stripped = line.strip()
        
        # Detect table rows (start with |)
        if stripped.startswith("|") and stripped.endswith("|"):
            if not in_table:
                # Add blank line before table
                if result and result[-1].strip():
                    result.append("")
            in_table = True
            result.append(stripped)
        else:
            if in_table and stripped:
                # Add blank line after table
                result.append("")
            in_table = False
            result.append(line)
    
    return "\n".join(result)


def preserve_code_blocks(text: str) -> str:
    """Ensure code blocks are properly formatted with language hints."""
    # Fix unclosed code blocks
    code_block_count = text.count("```")
    if code_block_count % 2 != 0:
        text += "\n```"
    
    return text


# ============================================================================
# WORKSPACE DETECTION
# ============================================================================

def get_platform() -> str:
    """Get current platform identifier."""
    if sys.platform == "darwin":
        return "darwin"
    elif sys.platform.startswith("linux"):
        return "linux"
    elif sys.platform == "win32":
        return "win32"
    else:
        return "darwin"  # Default fallback


def get_vscode_path() -> Path:
    """Get VS Code data path for current platform."""
    platform = get_platform()
    paths = VSCODE_PATHS.get(platform, VSCODE_PATHS["darwin"])
    
    # Prefer Insiders
    for edition in ["insiders", "stable"]:
        path = paths.get(edition)
        if path and path.exists():
            return path
    
    raise FileNotFoundError("No VS Code installation found")


def find_workspace_by_cwd() -> Optional[Path]:
    """Find workspace storage matching current working directory."""
    cwd = Path.cwd().resolve()
    cwd_name = cwd.name.lower()
    
    try:
        vscode_path = get_vscode_path()
    except FileNotFoundError:
        return None
    
    storage_root = vscode_path / "User" / "workspaceStorage"
    if not storage_root.exists():
        return None
    
    candidates = []
    
    for ws_dir in storage_root.iterdir():
        if not ws_dir.is_dir():
            continue
        
        workspace_json = ws_dir / "workspace.json"
        chat_sessions = ws_dir / "chatSessions"
        
        if not (workspace_json.exists() and chat_sessions.exists()):
            continue
        
        try:
            with open(workspace_json, "r") as f:
                ws_info = json.load(f)
            
            folder = ws_info.get("folder", "")
            
            # Match by folder name
            if cwd_name in folder.lower() or str(cwd) in folder:
                sessions = list(chat_sessions.glob("*.json"))
                if sessions:
                    total_size = sum(s.stat().st_size for s in sessions)
                    candidates.append({
                        "path": ws_dir,
                        "folder": folder,
                        "sessions": len(sessions),
                        "total_size": total_size,
                    })
        except (json.JSONDecodeError, PermissionError, OSError):
            continue
    
    if not candidates:
        return None
    
    # Return workspace with most/largest sessions
    candidates.sort(key=lambda x: x["total_size"], reverse=True)
    return candidates[0]["path"]


def find_workspace_by_name(name: str) -> Optional[Path]:
    """Find workspace storage by name pattern."""
    try:
        vscode_path = get_vscode_path()
    except FileNotFoundError:
        return None
    
    storage_root = vscode_path / "User" / "workspaceStorage"
    if not storage_root.exists():
        return None
    
    name_lower = name.lower()
    
    for ws_dir in storage_root.iterdir():
        if not ws_dir.is_dir():
            continue
        
        workspace_json = ws_dir / "workspace.json"
        chat_sessions = ws_dir / "chatSessions"
        
        if not (workspace_json.exists() and chat_sessions.exists()):
            continue
        
        try:
            with open(workspace_json, "r") as f:
                ws_info = json.load(f)
            
            folder = ws_info.get("folder", "")
            if name_lower in folder.lower():
                return ws_dir
        except (json.JSONDecodeError, PermissionError):
            continue
    
    return None


# ============================================================================
# SESSION PARSING
# ============================================================================

def get_chat_sessions(workspace_path: Path) -> List[Dict[str, Any]]:
    """Get all chat sessions from a workspace, sorted by size (largest first)."""
    chat_dir = workspace_path / "chatSessions"
    
    if not chat_dir.exists():
        return []
    
    sessions = []
    for chat_file in chat_dir.glob("*.json"):
        try:
            stat = chat_file.stat()
            sessions.append({
                "path": chat_file,
                "id": chat_file.stem,
                "modified": datetime.fromtimestamp(stat.st_mtime),
                "size": stat.st_size,
            })
        except (PermissionError, OSError):
            continue
    
    # Sort by size (largest = most content = current session)
    sessions.sort(key=lambda x: x["size"], reverse=True)
    return sessions


def parse_chat_session(session_path: Path) -> Dict[str, Any]:
    """Parse a chat session JSON file into structured format."""
    with open(session_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    parsed = {
        "version": data.get("version", "unknown"),
        "responder": data.get("responderUsername", "GitHub Copilot"),
        "location": data.get("initialLocation", "panel"),
        "requests": [],
        "milestones": [],
    }
    
    all_milestones = []
    
    for request in data.get("requests", []):
        req_entry = {
            "id": request.get("requestId", ""),
            "user_message": "",
            "agent_response": "",
            "agent_thinking": "",
            "tool_calls": [],
            "model": request.get("modelId", ""),
            "timestamp": None,
            "milestones": [],
        }
        
        # Extract user message
        message = request.get("message", {})
        if isinstance(message, dict):
            req_entry["user_message"] = sanitize_text(message.get("text", ""))
        elif isinstance(message, str):
            req_entry["user_message"] = sanitize_text(message)
        
        # Extract agent response
        response = request.get("response", [])
        if isinstance(response, list):
            response_parts = []
            thinking_parts = []
            tool_calls = []
            
            for item in response:
                if not isinstance(item, dict):
                    continue
                
                kind = item.get("kind")
                value = sanitize_text(item.get("value", ""))
                
                if kind == "thinking" and value:
                    thinking_parts.append(value)
                elif kind is None and value:
                    response_parts.append(value)
                elif kind == "markdownContent" and value:
                    response_parts.append(value)
                elif kind == "toolInvocationSerialized":
                    tool_calls.append({
                        "tool": item.get("toolId", ""),
                        "message": item.get("invocationMessage", ""),
                    })
            
            req_entry["agent_response"] = "\n\n".join(response_parts)
            req_entry["agent_thinking"] = "\n\n".join(thinking_parts)
            req_entry["tool_calls"] = tool_calls
        
        elif isinstance(response, dict):
            result = response.get("result", {})
            if isinstance(result, dict):
                value = result.get("value", "")
                req_entry["agent_response"] = sanitize_text(value)
        
        # Get timestamp
        timestamp = request.get("timestamp")
        if timestamp:
            try:
                req_entry["timestamp"] = datetime.fromisoformat(
                    timestamp.replace("Z", "+00:00")
                )
            except (ValueError, AttributeError):
                pass
        
        # Detect milestones
        combined_text = req_entry["user_message"] + " " + req_entry["agent_response"]
        req_milestones = detect_milestones(combined_text)
        req_entry["milestones"] = req_milestones
        all_milestones.extend(req_milestones)
        
        if req_entry["user_message"] or req_entry["agent_response"]:
            parsed["requests"].append(req_entry)
    
    parsed["milestones"] = list(set(all_milestones))
    return parsed


def format_for_llm(session_data: dict, include_metadata: bool = True) -> str:
    """Format parsed chat session into LLM-friendly flat text."""
    lines = []
    
    if include_metadata:
        lines.extend([
            "# COPILOT CHAT SESSION TRANSCRIPT",
            "",
            "## Environment",
            f"- **IDE**: {ENVIRONMENT['ide']}",
            f"- **Agent**: {ENVIRONMENT['agent']}",
            f"- **LLM**: {ENVIRONMENT['llm']}",
            f"- **OS**: {ENVIRONMENT['os']}",
            "",
            "## Session Info",
            f"- **Version**: {session_data['version']}",
            f"- **Responder**: {session_data['responder']}",
            f"- **Location**: {session_data['location']}",
            f"- **Total Exchanges**: {len(session_data['requests'])}",
            "",
            "---",
            "",
        ])
    
    for i, req in enumerate(session_data["requests"], 1):
        # Exchange header
        lines.append(f"## Exchange {i}")
        if req.get("timestamp"):
            lines.append(f"*Timestamp: {req['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}*")
        if req.get("model"):
            lines.append(f"*Model: {req['model']}*")
        lines.append("")
        
        # User message
        lines.append("### USER")
        lines.append("")
        lines.append(req["user_message"])
        lines.append("")
        
        # Agent thinking (if present)
        if req.get("agent_thinking"):
            lines.append("### AGENT REASONING")
            lines.append("")
            lines.append("<details>")
            lines.append("<summary>Click to expand thinking process</summary>")
            lines.append("")
            lines.append(req["agent_thinking"])
            lines.append("")
            lines.append("</details>")
            lines.append("")
        
        # Tool calls (if present)
        if req.get("tool_calls"):
            lines.append("### TOOL CALLS")
            lines.append("")
            for tc in req["tool_calls"]:
                tool_name = tc.get("tool", "unknown")
                tool_msg = tc.get("message", "")
                lines.append(f"- **{tool_name}**: {tool_msg}")
            lines.append("")
        
        # Agent response
        lines.append("### ASSISTANT")
        lines.append("")
        lines.append(req["agent_response"])
        lines.append("")
        lines.append("---")
        lines.append("")
    
    return "\n".join(lines)


def clean_text(text: str) -> str:
    """Clean text for better LLM consumption."""
    # Remove excessive whitespace while preserving code blocks
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        # Preserve code indentation
        if line.startswith('    ') or line.startswith('\t'):
            cleaned_lines.append(line)
        else:
            cleaned_lines.append(line.strip())
    
    # Remove multiple consecutive empty lines
    result = []
    prev_empty = False
    for line in cleaned_lines:
        is_empty = not line.strip()
        if is_empty and prev_empty:
            continue
        result.append(line)
        prev_empty = is_empty
    
    return '\n'.join(result)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main entry point."""
    print("=" * 60)
    print("VS Code Copilot Chat Extractor")
    print("=" * 60)
    print()
    
    # Print environment info
    print("## Environment Detection")
    for key, value in ENVIRONMENT.items():
        print(f"  {key}: {value}")
    print()
    
    # Detect VS Code installation
    try:
        vscode_path, edition = detect_vscode_installation()
        print(f"✓ Found VS Code {edition}: {vscode_path}")
    except FileNotFoundError as e:
        print(f"✗ Error: {e}")
        sys.exit(1)
    
    # Find workspace storage (for hydro_unified if available)
    try:
        workspace_path = find_workspace_storage(vscode_path, "hydro_unified")
        workspace_json = workspace_path / "workspace.json"
        with open(workspace_json, 'r') as f:
            ws_info = json.load(f)
        print(f"✓ Found workspace: {ws_info.get('folder', 'unknown')}")
    except FileNotFoundError as e:
        print(f"✗ Error: {e}")
        sys.exit(1)
    
    # Get chat sessions
    sessions = get_chat_sessions(workspace_path)
    print(f"✓ Found {len(sessions)} chat session(s)")
    print()
    
    if not sessions:
        print("No chat sessions to export.")
        sys.exit(0)
    
    # Show available sessions
    print("## Available Chat Sessions")
    for i, session in enumerate(sessions):
        print(f"  [{i}] {session['id'][:8]}... | Modified: {session['modified']} | Size: {session['size']:,} bytes")
    print()
    
    # Process the most recent session (or all if requested)
    export_all = "--all" in sys.argv
    sessions_to_export = sessions if export_all else [sessions[0]]
    
    # Output to root folder
    output_dir = Path.cwd()
    
    print("## Exporting Chat Sessions")
    for session in sessions_to_export:
        print(f"  Processing: {session['id'][:8]}...")
        
        try:
            parsed = parse_chat_session(session["path"])
            formatted = format_for_llm(parsed)
            cleaned = clean_text(formatted)
            
            # Generate output filename: SessionName_YYYYMMDD-HH:MM.md
            timestamp = session["modified"].strftime("%Y%m%d-%H:%M")
            output_file = output_dir / f"session_{session['id'][:8]}_{timestamp}.md"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(cleaned)
            
            print(f"    ✓ Exported to: {output_file}")
            print(f"    ✓ Exchanges: {len(parsed['requests'])}")
            
        except Exception as e:
            print(f"    ✗ Error: {e}")
    
    print()
    print("=" * 60)
    print("Export Complete!")
    print(f"Output directory: {output_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()
